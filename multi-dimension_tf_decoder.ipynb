{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Tensorflow Example proto decoder for object detection.\n",
    "\n",
    "A decoder to decode string tensors containing serialized tensorflow.Example\n",
    "protos for object detection.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.core import data_decoder\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.protos import input_reader_pb2\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "slim_example_decoder = tf.contrib.slim.tfexample_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ClassTensorHandler(slim_example_decoder.Tensor):\n",
    "    \"\"\"An ItemHandler to fetch class ids from class text.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                             tensor_key,\n",
    "                             label_map_proto_file,\n",
    "                             shape_keys=None,\n",
    "                             shape=None,\n",
    "                             default_value=''):\n",
    "        \"\"\"Initializes the LookupTensor handler.\n",
    "\n",
    "        Simply calls a vocabulary (most often, a label mapping) lookup.\n",
    "\n",
    "        Args:\n",
    "            tensor_key: the name of the `TFExample` feature to read the tensor from.\n",
    "            label_map_proto_file: File path to a text format LabelMapProto message\n",
    "                mapping class text to id.\n",
    "            shape_keys: Optional name or list of names of the TF-Example feature in\n",
    "                which the tensor shape is stored. If a list, then each corresponds to\n",
    "                one dimension of the shape.\n",
    "            shape: Optional output shape of the `Tensor`. If provided, the `Tensor` is\n",
    "                reshaped accordingly.\n",
    "            default_value: The value used when the `tensor_key` is not found in a\n",
    "                particular `TFExample`.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if both `shape_keys` and `shape` are specified.\n",
    "        \"\"\"\n",
    "        name_to_id = label_map_util.get_label_map_dict(\n",
    "                label_map_proto_file, use_display_name=False)\n",
    "        # We use a default_value of -1, but we expect all labels to be contained\n",
    "        # in the label map.\n",
    "        name_to_id_table = tf.contrib.lookup.HashTable(\n",
    "                initializer=tf.contrib.lookup.KeyValueTensorInitializer(\n",
    "                        keys=tf.constant(list(name_to_id.keys())),\n",
    "                        values=tf.constant(list(name_to_id.values()), dtype=tf.int64)),\n",
    "                default_value=-1)\n",
    "        display_name_to_id = label_map_util.get_label_map_dict(\n",
    "                label_map_proto_file, use_display_name=True)\n",
    "        # We use a default_value of -1, but we expect all labels to be contained\n",
    "        # in the label map.\n",
    "        display_name_to_id_table = tf.contrib.lookup.HashTable(\n",
    "                initializer=tf.contrib.lookup.KeyValueTensorInitializer(\n",
    "                        keys=tf.constant(list(display_name_to_id.keys())),\n",
    "                        values=tf.constant(\n",
    "                                list(display_name_to_id.values()), dtype=tf.int64)),\n",
    "                default_value=-1)\n",
    "\n",
    "        self._name_to_id_table = name_to_id_table\n",
    "        self._display_name_to_id_table = display_name_to_id_table\n",
    "        super(_ClassTensorHandler, self).__init__(tensor_key, shape_keys, shape,\n",
    "                                                                                            default_value)\n",
    "\n",
    "    def tensors_to_item(self, keys_to_tensors):\n",
    "        unmapped_tensor = super(_ClassTensorHandler,\n",
    "                                                        self).tensors_to_item(keys_to_tensors)\n",
    "        return tf.maximum(self._name_to_id_table.lookup(unmapped_tensor),\n",
    "                                            self._display_name_to_id_table.lookup(unmapped_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BackupHandler(slim_example_decoder.ItemHandler):\n",
    "    \"\"\"An ItemHandler that tries two ItemHandlers in order.\"\"\"\n",
    "\n",
    "    def __init__(self, handler, backup):\n",
    "        \"\"\"Initializes the BackupHandler handler.\n",
    "\n",
    "        If the first Handler's tensors_to_item returns a Tensor with no elements,\n",
    "        the second Handler is used.\n",
    "\n",
    "        Args:\n",
    "            handler: The primary ItemHandler.\n",
    "            backup: The backup ItemHandler.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if either is not an ItemHandler.\n",
    "        \"\"\"\n",
    "        if not isinstance(handler, slim_example_decoder.ItemHandler):\n",
    "            raise ValueError('Primary handler is of type %s instead of ItemHandler' %\n",
    "                                             type(handler))\n",
    "        if not isinstance(backup, slim_example_decoder.ItemHandler):\n",
    "            raise ValueError(\n",
    "                    'Backup handler is of type %s instead of ItemHandler' % type(backup))\n",
    "        self._handler = handler\n",
    "        self._backup = backup\n",
    "        super(_BackupHandler, self).__init__(handler.keys + backup.keys)\n",
    "\n",
    "    def tensors_to_item(self, keys_to_tensors):\n",
    "        item = self._handler.tensors_to_item(keys_to_tensors)\n",
    "        return tf.cond(\n",
    "                pred=tf.equal(tf.reduce_prod(tf.shape(item)), 0),\n",
    "                true_fn=lambda: self._backup.tensors_to_item(keys_to_tensors),\n",
    "                false_fn=lambda: item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfExampleDecoder(data_decoder.DataDecoder):\n",
    "    \"\"\"Tensorflow Example proto decoder.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                             load_instance_masks=False,\n",
    "                             instance_mask_type=input_reader_pb2.NUMERICAL_MASKS,\n",
    "                             label_map_proto_file=None,\n",
    "                             use_display_name=False,\n",
    "                             dct_method='',\n",
    "                             num_keypoints=0,\n",
    "                             num_additional_channels=0):\n",
    "        \"\"\"Constructor sets keys_to_features and items_to_handlers.\n",
    "\n",
    "        Args:\n",
    "            load_instance_masks: whether or not to load and handle instance masks.\n",
    "            instance_mask_type: type of instance masks. Options are provided in\n",
    "                input_reader.proto. This is only used if `load_instance_masks` is True.\n",
    "            label_map_proto_file: a file path to a\n",
    "                object_detection.protos.StringIntLabelMap proto. If provided, then the\n",
    "                mapped IDs of 'image/object/class/text' will take precedence over the\n",
    "                existing 'image/object/class/label' ID.  Also, if provided, it is\n",
    "                assumed that 'image/object/class/text' will be in the data.\n",
    "            use_display_name: whether or not to use the `display_name` for label\n",
    "                mapping (instead of `name`).  Only used if label_map_proto_file is\n",
    "                provided.\n",
    "            dct_method: An optional string. Defaults to None. It only takes\n",
    "                effect when image format is jpeg, used to specify a hint about the\n",
    "                algorithm used for jpeg decompression. Currently valid values\n",
    "                are ['INTEGER_FAST', 'INTEGER_ACCURATE']. The hint may be ignored, for\n",
    "                example, the jpeg library does not have that specific option.\n",
    "            num_keypoints: the number of keypoints per object.\n",
    "            num_additional_channels: how many additional channels to use.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `instance_mask_type` option is not one of\n",
    "                input_reader_pb2.DEFAULT, input_reader_pb2.NUMERICAL, or\n",
    "                input_reader_pb2.PNG_MASKS.\n",
    "        \"\"\"\n",
    "        # TODO(rathodv): delete unused `use_display_name` argument once we change\n",
    "        # other decoders to handle label maps similarly.\n",
    "        def _read_image(self, keys_to_tensors):\n",
    "            image_encoded = keys_to_tensors['image/encoded']\n",
    "            height = keys_to_tensors['image/height']\n",
    "            width = keys_to_tensors['image/width']\n",
    "            channels = keys_to_tensors['image/channels']\n",
    "            to_shape = tf.cast(tf.stack([height, width, channels]), tf.int32)\n",
    "            image = tf.reshape(tf.decode_raw(image_encoded, tf.uint8), to_shape)\n",
    "            return image\n",
    "        \n",
    "        del use_display_name\n",
    "        self.keys_to_features = {\n",
    "                'image/encoded':\n",
    "                        tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "                'image/format':\n",
    "                        tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n",
    "                'image/filename':\n",
    "                        tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "                'image/key/sha256':\n",
    "                        tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "                'image/source_id':\n",
    "                        tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "                'image/height':\n",
    "                        tf.FixedLenFeature((), tf.int64, default_value=1),\n",
    "                'image/width':\n",
    "                        tf.FixedLenFeature((), tf.int64, default_value=1),\n",
    "                # Image-level labels.\n",
    "                'image/class/text':\n",
    "                        tf.VarLenFeature(tf.string),\n",
    "                'image/class/label':\n",
    "                        tf.VarLenFeature(tf.int64),\n",
    "                # Object boxes and classes.\n",
    "                'image/object/bbox/xmin':\n",
    "                        tf.VarLenFeature(tf.float32),\n",
    "                'image/object/bbox/xmax':\n",
    "                        tf.VarLenFeature(tf.float32),\n",
    "                'image/object/bbox/ymin':\n",
    "                        tf.VarLenFeature(tf.float32),\n",
    "                'image/object/bbox/ymax':\n",
    "                        tf.VarLenFeature(tf.float32),\n",
    "                'image/object/class/label':\n",
    "                        tf.VarLenFeature(tf.int64),\n",
    "                'image/object/class/text':\n",
    "                        tf.VarLenFeature(tf.string),\n",
    "                'image/object/area':\n",
    "                        tf.VarLenFeature(tf.float32),\n",
    "                'image/object/is_crowd':\n",
    "                        tf.VarLenFeature(tf.int64),\n",
    "                'image/object/difficult':\n",
    "                        tf.VarLenFeature(tf.int64),\n",
    "                'image/object/group_of':\n",
    "                        tf.VarLenFeature(tf.int64),\n",
    "                'image/object/weight':\n",
    "                        tf.VarLenFeature(tf.float32),\n",
    "                'image/channels': \n",
    "                        tf.FixedLenFeature((), tf.int64, 1),\n",
    "        }\n",
    "        # We are checking `dct_method` instead of passing it directly in order to\n",
    "        # ensure TF version 1.6 compatibility.\n",
    "        if dct_method:\n",
    "            image = slim_example_decoder.Image(\n",
    "                    image_key='image/encoded',\n",
    "                    format_key='image/format',\n",
    "                    channels=3,\n",
    "                    dct_method=dct_method)\n",
    "            additional_channel_image = slim_example_decoder.Image(\n",
    "                    image_key='image/additional_channels/encoded',\n",
    "                    format_key='image/format',\n",
    "                    channels=1,\n",
    "                    repeated=True,\n",
    "                    dct_method=dct_method)\n",
    "        else:\n",
    "            image = slim_example_decoder.Image(\n",
    "                    image_key='image/encoded', format_key='image/format', channels=3)\n",
    "            additional_channel_image = slim_example_decoder.Image(\n",
    "                    image_key='image/additional_channels/encoded',\n",
    "                    format_key='image/format',\n",
    "                    channels=1,\n",
    "                    repeated=True)\n",
    "        self.items_to_handlers = {\n",
    "            fields.InputDataFields.image:\n",
    "                slim_example_decoder.ItemHandlerCallback(\n",
    "                keys=['image/encoded', 'image/height', 'image/width', 'image/channels'],\n",
    "                func=self._read_image\n",
    "        )\n",
    "                fields.InputDataFields.source_id: (\n",
    "                        slim_example_decoder.Tensor('image/source_id')),\n",
    "                fields.InputDataFields.key: (\n",
    "                        slim_example_decoder.Tensor('image/key/sha256')),\n",
    "                fields.InputDataFields.filename: (\n",
    "                        slim_example_decoder.Tensor('image/filename')),\n",
    "                # Object boxes and classes.\n",
    "                fields.InputDataFields.groundtruth_boxes: (\n",
    "                        slim_example_decoder.BoundingBox(['ymin', 'xmin', 'ymax', 'xmax'],\n",
    "                                                                                         'image/object/bbox/')),\n",
    "                fields.InputDataFields.groundtruth_area:\n",
    "                        slim_example_decoder.Tensor('image/object/area'),\n",
    "                fields.InputDataFields.groundtruth_is_crowd: (\n",
    "                        slim_example_decoder.Tensor('image/object/is_crowd')),\n",
    "                fields.InputDataFields.groundtruth_difficult: (\n",
    "                        slim_example_decoder.Tensor('image/object/difficult')),\n",
    "                fields.InputDataFields.groundtruth_group_of: (\n",
    "                        slim_example_decoder.Tensor('image/object/group_of')),\n",
    "                fields.InputDataFields.groundtruth_weights: (\n",
    "                        slim_example_decoder.Tensor('image/object/weight')),\n",
    "        }\n",
    "        if num_additional_channels > 0:\n",
    "            self.keys_to_features[\n",
    "                    'image/additional_channels/encoded'] = tf.FixedLenFeature(\n",
    "                            (num_additional_channels,), tf.string)\n",
    "            self.items_to_handlers[\n",
    "                    fields.InputDataFields.\n",
    "                    image_additional_channels] = additional_channel_image\n",
    "        self._num_keypoints = num_keypoints\n",
    "        if num_keypoints > 0:\n",
    "            self.keys_to_features['image/object/keypoint/x'] = (\n",
    "                    tf.VarLenFeature(tf.float32))\n",
    "            self.keys_to_features['image/object/keypoint/y'] = (\n",
    "                    tf.VarLenFeature(tf.float32))\n",
    "            self.items_to_handlers[fields.InputDataFields.groundtruth_keypoints] = (\n",
    "                    slim_example_decoder.ItemHandlerCallback(\n",
    "                            ['image/object/keypoint/y', 'image/object/keypoint/x'],\n",
    "                            self._reshape_keypoints))\n",
    "        if load_instance_masks:\n",
    "            if instance_mask_type in (input_reader_pb2.DEFAULT,\n",
    "                                                                input_reader_pb2.NUMERICAL_MASKS):\n",
    "                self.keys_to_features['image/object/mask'] = (\n",
    "                        tf.VarLenFeature(tf.float32))\n",
    "                self.items_to_handlers[\n",
    "                        fields.InputDataFields.groundtruth_instance_masks] = (\n",
    "                                slim_example_decoder.ItemHandlerCallback(\n",
    "                                        ['image/object/mask', 'image/height', 'image/width'],\n",
    "                                        self._reshape_instance_masks))\n",
    "            elif instance_mask_type == input_reader_pb2.PNG_MASKS:\n",
    "                self.keys_to_features['image/object/mask'] = tf.VarLenFeature(tf.string)\n",
    "                self.items_to_handlers[\n",
    "                        fields.InputDataFields.groundtruth_instance_masks] = (\n",
    "                                slim_example_decoder.ItemHandlerCallback(\n",
    "                                        ['image/object/mask', 'image/height', 'image/width'],\n",
    "                                        self._decode_png_instance_masks))\n",
    "            else:\n",
    "                raise ValueError('Did not recognize the `instance_mask_type` option.')\n",
    "        if label_map_proto_file:\n",
    "            # If the label_map_proto is provided, try to use it in conjunction with\n",
    "            # the class text, and fall back to a materialized ID.\n",
    "            label_handler = _BackupHandler(\n",
    "                    _ClassTensorHandler(\n",
    "                            'image/object/class/text', label_map_proto_file,\n",
    "                            default_value=''),\n",
    "                    slim_example_decoder.Tensor('image/object/class/label'))\n",
    "            image_label_handler = _BackupHandler(\n",
    "                    _ClassTensorHandler(\n",
    "                            fields.TfExampleFields.image_class_text,\n",
    "                            label_map_proto_file,\n",
    "                            default_value=''),\n",
    "                    slim_example_decoder.Tensor(fields.TfExampleFields.image_class_label))\n",
    "        else:\n",
    "            label_handler = slim_example_decoder.Tensor('image/object/class/label')\n",
    "            image_label_handler = slim_example_decoder.Tensor(\n",
    "                    fields.TfExampleFields.image_class_label)\n",
    "        self.items_to_handlers[\n",
    "                fields.InputDataFields.groundtruth_classes] = label_handler\n",
    "        self.items_to_handlers[\n",
    "                fields.InputDataFields.groundtruth_image_classes] = image_label_handler\n",
    "\n",
    "    def decode(self, tf_example_string_tensor):\n",
    "        \"\"\"Decodes serialized tensorflow example and returns a tensor dictionary.\n",
    "\n",
    "        Args:\n",
    "            tf_example_string_tensor: a string tensor holding a serialized tensorflow\n",
    "                example proto.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary of the following tensors.\n",
    "            fields.InputDataFields.image - 3D uint8 tensor of shape [None, None, 3]\n",
    "                containing image.\n",
    "            fields.InputDataFields.original_image_spatial_shape - 1D int32 tensor of\n",
    "                shape [2] containing shape of the image.\n",
    "            fields.InputDataFields.source_id - string tensor containing original\n",
    "                image id.\n",
    "            fields.InputDataFields.key - string tensor with unique sha256 hash key.\n",
    "            fields.InputDataFields.filename - string tensor with original dataset\n",
    "                filename.\n",
    "            fields.InputDataFields.groundtruth_boxes - 2D float32 tensor of shape\n",
    "                [None, 4] containing box corners.\n",
    "            fields.InputDataFields.groundtruth_classes - 1D int64 tensor of shape\n",
    "                [None] containing classes for the boxes.\n",
    "            fields.InputDataFields.groundtruth_weights - 1D float32 tensor of\n",
    "                shape [None] indicating the weights of groundtruth boxes.\n",
    "            fields.InputDataFields.groundtruth_area - 1D float32 tensor of shape\n",
    "                [None] containing containing object mask area in pixel squared.\n",
    "            fields.InputDataFields.groundtruth_is_crowd - 1D bool tensor of shape\n",
    "                [None] indicating if the boxes enclose a crowd.\n",
    "\n",
    "        Optional:\n",
    "            fields.InputDataFields.image_additional_channels - 3D uint8 tensor of\n",
    "                shape [None, None, num_additional_channels]. 1st dim is height; 2nd dim\n",
    "                is width; 3rd dim is the number of additional channels.\n",
    "            fields.InputDataFields.groundtruth_difficult - 1D bool tensor of shape\n",
    "                [None] indicating if the boxes represent `difficult` instances.\n",
    "            fields.InputDataFields.groundtruth_group_of - 1D bool tensor of shape\n",
    "                [None] indicating if the boxes represent `group_of` instances.\n",
    "            fields.InputDataFields.groundtruth_keypoints - 3D float32 tensor of\n",
    "                shape [None, None, 2] containing keypoints, where the coordinates of\n",
    "                the keypoints are ordered (y, x).\n",
    "            fields.InputDataFields.groundtruth_instance_masks - 3D float32 tensor of\n",
    "                shape [None, None, None] containing instance masks.\n",
    "            fields.InputDataFields.groundtruth_image_classes - 1D uint64 of shape\n",
    "                [None] containing classes for the boxes.\n",
    "        \"\"\"\n",
    "        serialized_example = tf.reshape(tf_example_string_tensor, shape=[])\n",
    "        decoder = slim_example_decoder.TFExampleDecoder(self.keys_to_features,\n",
    "                                                                                                        self.items_to_handlers)\n",
    "        keys = decoder.list_items()\n",
    "        tensors = decoder.decode(serialized_example, items=keys)\n",
    "        tensor_dict = dict(zip(keys, tensors))\n",
    "        is_crowd = fields.InputDataFields.groundtruth_is_crowd\n",
    "        tensor_dict[is_crowd] = tf.cast(tensor_dict[is_crowd], dtype=tf.bool)\n",
    "        tensor_dict[fields.InputDataFields.image].set_shape([None, None, 3])\n",
    "        tensor_dict[fields.InputDataFields.original_image_spatial_shape] = tf.shape(\n",
    "                tensor_dict[fields.InputDataFields.image])[:2]\n",
    "\n",
    "        if fields.InputDataFields.image_additional_channels in tensor_dict:\n",
    "            channels = tensor_dict[fields.InputDataFields.image_additional_channels]\n",
    "            channels = tf.squeeze(channels, axis=3)\n",
    "            channels = tf.transpose(channels, perm=[1, 2, 0])\n",
    "            tensor_dict[fields.InputDataFields.image_additional_channels] = channels\n",
    "\n",
    "        def default_groundtruth_weights():\n",
    "            return tf.ones(\n",
    "                    [tf.shape(tensor_dict[fields.InputDataFields.groundtruth_boxes])[0]],\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "        tensor_dict[fields.InputDataFields.groundtruth_weights] = tf.cond(\n",
    "                tf.greater(\n",
    "                        tf.shape(\n",
    "                                tensor_dict[fields.InputDataFields.groundtruth_weights])[0],\n",
    "                        0), lambda: tensor_dict[fields.InputDataFields.groundtruth_weights],\n",
    "                default_groundtruth_weights)\n",
    "        return tensor_dict\n",
    "\n",
    "    def _reshape_keypoints(self, keys_to_tensors):\n",
    "        \"\"\"Reshape keypoints.\n",
    "\n",
    "        The instance segmentation masks are reshaped to [num_instances,\n",
    "        num_keypoints, 2].\n",
    "\n",
    "        Args:\n",
    "            keys_to_tensors: a dictionary from keys to tensors.\n",
    "\n",
    "        Returns:\n",
    "            A 3-D float tensor of shape [num_instances, num_keypoints, 2] with values\n",
    "                in {0, 1}.\n",
    "        \"\"\"\n",
    "        y = keys_to_tensors['image/object/keypoint/y']\n",
    "        if isinstance(y, tf.SparseTensor):\n",
    "            y = tf.sparse_tensor_to_dense(y)\n",
    "        y = tf.expand_dims(y, 1)\n",
    "        x = keys_to_tensors['image/object/keypoint/x']\n",
    "        if isinstance(x, tf.SparseTensor):\n",
    "            x = tf.sparse_tensor_to_dense(x)\n",
    "        x = tf.expand_dims(x, 1)\n",
    "        keypoints = tf.concat([y, x], 1)\n",
    "        keypoints = tf.reshape(keypoints, [-1, self._num_keypoints, 2])\n",
    "        return keypoints\n",
    "\n",
    "    def _reshape_instance_masks(self, keys_to_tensors):\n",
    "        \"\"\"Reshape instance segmentation masks.\n",
    "\n",
    "        The instance segmentation masks are reshaped to [num_instances, height,\n",
    "        width].\n",
    "\n",
    "        Args:\n",
    "            keys_to_tensors: a dictionary from keys to tensors.\n",
    "\n",
    "        Returns:\n",
    "            A 3-D float tensor of shape [num_instances, height, width] with values\n",
    "                in {0, 1}.\n",
    "        \"\"\"\n",
    "        height = keys_to_tensors['image/height']\n",
    "        width = keys_to_tensors['image/width']\n",
    "        to_shape = tf.cast(tf.stack([-1, height, width]), tf.int32)\n",
    "        masks = keys_to_tensors['image/object/mask']\n",
    "        if isinstance(masks, tf.SparseTensor):\n",
    "            masks = tf.sparse_tensor_to_dense(masks)\n",
    "        masks = tf.reshape(tf.to_float(tf.greater(masks, 0.0)), to_shape)\n",
    "        return tf.cast(masks, tf.float32)\n",
    "\n",
    "    def _decode_png_instance_masks(self, keys_to_tensors):\n",
    "        \"\"\"Decode PNG instance segmentation masks and stack into dense tensor.\n",
    "\n",
    "        The instance segmentation masks are reshaped to [num_instances, height,\n",
    "        width].\n",
    "\n",
    "        Args:\n",
    "            keys_to_tensors: a dictionary from keys to tensors.\n",
    "\n",
    "        Returns:\n",
    "            A 3-D float tensor of shape [num_instances, height, width] with values\n",
    "                in {0, 1}.\n",
    "        \"\"\"\n",
    "\n",
    "        def decode_png_mask(image_buffer):\n",
    "            image = tf.squeeze(\n",
    "                    tf.image.decode_image(image_buffer, channels=1), axis=2)\n",
    "            image.set_shape([None, None])\n",
    "            image = tf.to_float(tf.greater(image, 0))\n",
    "            return image\n",
    "\n",
    "        png_masks = keys_to_tensors['image/object/mask']\n",
    "        height = keys_to_tensors['image/height']\n",
    "        width = keys_to_tensors['image/width']\n",
    "        if isinstance(png_masks, tf.SparseTensor):\n",
    "            png_masks = tf.sparse_tensor_to_dense(png_masks, default_value='')\n",
    "        return tf.cond(\n",
    "                tf.greater(tf.size(png_masks), 0),\n",
    "                lambda: tf.map_fn(decode_png_mask, png_masks, dtype=tf.float32),\n",
    "                lambda: tf.zeros(tf.to_int32(tf.stack([0, height, width]))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
