{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('/Users/johnmorin/KaylaTek/Data/Flight_5_with_ground_truth/frame_000000.tif')\n",
    "test_image2 = cv2.imread('/Users/johnmorin/KaylaTek/Data/Flight_5_with_ground_truth/frame_000001.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_im_loc = '/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/train/cam_image1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_image_cv2 = cv2.imread(jpg_im_loc)\n",
    "jpg_image_PIL = Image.open(jpg_im_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.gfile.GFile(jpg_im_loc, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_image = tf.image.convert_image_dtype(\n",
    "    image=test_image,\n",
    "    dtype='uint8',\n",
    "    saturate=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_image2 = tf.image.convert_image_dtype(\n",
    "    image=test_image2,\n",
    "    dtype='uint8',\n",
    "    saturate=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_tf_image = tf.image.convert_image_dtype(\n",
    "    image=jpg_image_cv2,\n",
    "    dtype='uint8',\n",
    "    saturate=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_on_image_tensors(images,\n",
    "                                        boxes,\n",
    "                                        classes,\n",
    "                                        scores,\n",
    "                                        category_index,\n",
    "                                        original_image_spatial_shape=None,\n",
    "                                        true_image_shape=None,\n",
    "                                        instance_masks=None,\n",
    "                                        keypoints=None,\n",
    "                                        max_boxes_to_draw=20,\n",
    "                                        min_score_thresh=0.2,\n",
    "                                        use_normalized_coordinates=True):\n",
    "    \"\"\"Draws bounding boxes, masks, and keypoints on batch of image tensors.\n",
    "    Args:\n",
    "        images: A 4D uint8 image tensor of shape [N, H, W, C]. If C > 3, additional\n",
    "            channels will be ignored. If C = 1, then we convert the images to RGB\n",
    "            images.\n",
    "        boxes: [N, max_detections, 4] float32 tensor of detection boxes.\n",
    "        classes: [N, max_detections] int tensor of detection classes. Note that\n",
    "            classes are 1-indexed.\n",
    "        scores: [N, max_detections] float32 tensor of detection scores.\n",
    "        category_index: a dict that maps integer ids to category dicts. e.g.\n",
    "            {1: {1: 'dog'}, 2: {2: 'cat'}, ...}\n",
    "        original_image_spatial_shape: [N, 2] tensor containing the spatial size of\n",
    "            the original image.\n",
    "        true_image_shape: [N, 3] tensor containing the spatial size of unpadded\n",
    "            original_image.\n",
    "        instance_masks: A 4D uint8 tensor of shape [N, max_detection, H, W] with\n",
    "            instance masks.\n",
    "        keypoints: A 4D float32 tensor of shape [N, max_detection, num_keypoints, 2]\n",
    "            with keypoints.\n",
    "        max_boxes_to_draw: Maximum number of boxes to draw on an image. Default 20.\n",
    "        min_score_thresh: Minimum score threshold for visualization. Default 0.2.\n",
    "        use_normalized_coordinates: Whether to assume boxes and kepoints are in\n",
    "            normalized coordinates (as opposed to absolute coordiantes).\n",
    "            Default is True.\n",
    "    Returns:\n",
    "        4D image tensor of type uint8, with boxes drawn on top.\n",
    "    \"\"\"\n",
    "    # Additional channels are being ignored.\n",
    "    if images.shape[3] > 3:\n",
    "        images = images[:, :, :, 0:3]\n",
    "    elif images.shape[3] == 1:\n",
    "        images = tf.image.grayscale_to_rgb(images)\n",
    "    visualization_keyword_args = {\n",
    "            'use_normalized_coordinates': use_normalized_coordinates,\n",
    "            'max_boxes_to_draw': max_boxes_to_draw,\n",
    "            'min_score_thresh': min_score_thresh,\n",
    "            'agnostic_mode': False,\n",
    "            'line_thickness': 4\n",
    "    }\n",
    "    if true_image_shape is None:\n",
    "        true_shapes = tf.constant(-1, shape=[images.shape.as_list()[0], 3])\n",
    "    else:\n",
    "        true_shapes = true_image_shape\n",
    "    if original_image_spatial_shape is None:\n",
    "        original_shapes = tf.constant(-1, shape=[images.shape.as_list()[0], 2])\n",
    "    else:\n",
    "        original_shapes = original_image_spatial_shape\n",
    "\n",
    "    if instance_masks is not None and keypoints is None:\n",
    "        visualize_boxes_fn = functools.partial(\n",
    "                _visualize_boxes_and_masks,\n",
    "                category_index=category_index,\n",
    "                **visualization_keyword_args)\n",
    "        elems = [\n",
    "                true_shapes, original_shapes, images, boxes, classes, scores,\n",
    "                instance_masks\n",
    "        ]\n",
    "    elif instance_masks is None and keypoints is not None:\n",
    "        visualize_boxes_fn = functools.partial(\n",
    "                _visualize_boxes_and_keypoints,\n",
    "                category_index=category_index,\n",
    "                **visualization_keyword_args)\n",
    "        elems = [\n",
    "                true_shapes, original_shapes, images, boxes, classes, scores, keypoints\n",
    "        ]\n",
    "    elif instance_masks is not None and keypoints is not None:\n",
    "        visualize_boxes_fn = functools.partial(\n",
    "                _visualize_boxes_and_masks_and_keypoints,\n",
    "                category_index=category_index,\n",
    "                **visualization_keyword_args)\n",
    "        elems = [\n",
    "                true_shapes, original_shapes, images, boxes, classes, scores,\n",
    "                instance_masks, keypoints\n",
    "        ]\n",
    "    else:\n",
    "        visualize_boxes_fn = functools.partial(\n",
    "                _visualize_boxes,\n",
    "                category_index=category_index,\n",
    "                **visualization_keyword_args)\n",
    "        elems = [\n",
    "                true_shapes, original_shapes, images, boxes, classes, scores\n",
    "        ]\n",
    "\n",
    "    def draw_boxes(image_and_detections):\n",
    "        \"\"\"Draws boxes on image.\"\"\"\n",
    "        true_shape = image_and_detections[0]\n",
    "        original_shape = image_and_detections[1]\n",
    "        if true_image_shape is not None:\n",
    "            image = shape_utils.pad_or_clip_nd(image_and_detections[2],\n",
    "                                                                                 [true_shape[0], true_shape[1], 3])\n",
    "        if original_image_spatial_shape is not None:\n",
    "            image_and_detections[2] = _resize_original_image(image, original_shape)\n",
    "\n",
    "        image_with_boxes = tf.py_func(visualize_boxes_fn, image_and_detections[2:],\n",
    "                                                                    tf.uint8)\n",
    "        return image_with_boxes\n",
    "\n",
    "    images = tf.map_fn(draw_boxes, elems, dtype=tf.uint8, back_prop=False)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _visualize_boxes(image, boxes, classes, scores, category_index, **kwargs):\n",
    "    return visualize_boxes_and_labels_on_image_array(\n",
    "      image, boxes, classes, scores, category_index=category_index, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_image.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_image = tf.stack(\n",
    "    [tf_image, tf_image2],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_image.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"test_2:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(tf.summary.image(\n",
    "    name='test',\n",
    "    tensor=tf_image\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "slice index 0 of dimension 0 out of bounds. for 'map/TensorArrayUnstack_3/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1588\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 0 of dimension 0 out of bounds. for 'map/TensorArrayUnstack_3/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-81083c9a3820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                      \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                      \u001b[0mcategory_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                                     )\n",
      "\u001b[0;32m<ipython-input-10-9e6a5e8608e6>\u001b[0m in \u001b[0;36mdraw_bounding_boxes_on_image_tensors\u001b[0;34m(images, boxes, classes, scores, category_index, original_image_spatial_shape, true_image_shape, instance_masks, keypoints, max_boxes_to_draw, min_score_thresh, use_normalized_coordinates)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage_with_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;31m# Unpack elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     elems_ta = [\n\u001b[0;32m--> 423\u001b[0;31m         elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;31m# Unpack elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     elems_ta = [\n\u001b[0;32m--> 423\u001b[0;31m         elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \"\"\"\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_add_should_use_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m   return tf_decorator.make_decorator(\n\u001b[1;32m    120\u001b[0m       \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'should_use_result'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, value, name)\u001b[0m\n\u001b[1;32m    905\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshape\u001b[0m \u001b[0minference\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \"\"\"\n\u001b[0;32m--> 907\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_should_use\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_use_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \"\"\"\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_add_should_use_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m   return tf_decorator.make_decorator(\n\u001b[1;32m    120\u001b[0m       \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'should_use_result'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, value, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;34m\"\"\"See TensorArray.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TensorArrayUnstack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m       \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m       return self.scatter(\n\u001b[1;32m    331\u001b[0m           indices=math_ops.range(0, num_elements), value=value, name=name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8230\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8231\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8232\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8233\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8234\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3414\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1756\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1757\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: slice index 0 of dimension 0 out of bounds. for 'map/TensorArrayUnstack_3/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>."
     ]
    }
   ],
   "source": [
    "draw_bounding_boxes_on_image_tensors(images=stacked_image,\n",
    "                                     boxes=[[(1074/1280), (438/1024), (1096/1280), (455/1024)], 1, 4], \n",
    "                                     classes=['target', 1],\n",
    "                                     scores=[1, 1],\n",
    "                                     category_index={1: {1: 'target'}}\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image_array(image,\n",
    "                                     ymin,\n",
    "                                     xmin,\n",
    "                                     ymax,\n",
    "                                     xmax,\n",
    "                                     color='red',\n",
    "                                     thickness=4,\n",
    "                                     display_str_list=(),\n",
    "                                     use_normalized_coordinates=True):\n",
    "    \"\"\"Adds a bounding box to an image (numpy array).\n",
    "    Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "    normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "    Args:\n",
    "        image: a numpy array with shape [height, width, 3].\n",
    "        ymin: ymin of bounding box.\n",
    "        xmin: xmin of bounding box.\n",
    "        ymax: ymax of bounding box.\n",
    "        xmax: xmax of bounding box.\n",
    "        color: color to draw bounding box. Default is red.\n",
    "        thickness: line thickness. Default value is 4.\n",
    "        display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "        use_normalized_coordinates: If True (default), treat coordinates\n",
    "        ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "        coordinates as absolute.\n",
    "    \"\"\"\n",
    "    image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "    draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "    np.copyto(image, np.array(image_pil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.image.draw_bounding_boxes(\n",
    "    [tf_image],\n",
    "    (1074/1280), (438/1024), (1096/1280), (455/1024),\n",
    "    name='Target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_tf_image = tf.image.decode_jpeg(\n",
    "    jpg_image_cv2.tostring(),\n",
    "    channels=0,\n",
    "    ratio=1,\n",
    "    fancy_upscaling=True,\n",
    "    try_recover_truncated=False,\n",
    "    acceptable_fraction=1,\n",
    "    dct_method='',\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_tf_image2 = tf.image.decode_image(\n",
    "    contents=jpg_image_cv2.tostring(),\n",
    "    channels=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, ?, ?)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv2_tf_image))\n",
    "print(cv2_tf_image.shape)\n",
    "print(type(cv2_tf_image2))\n",
    "print(cv2_tf_image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL_tf_image = tf.image.decode_jpeg(\n",
    "    PIL_jpg,\n",
    "    channels=0,\n",
    "    ratio=1,\n",
    "    fancy_upscaling=True,\n",
    "    try_recover_truncated=False,\n",
    "    acceptable_fraction=1,\n",
    "    dct_method='',\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL_tf_image2 = tf.image.decode_image(\n",
    "    contents=PIL_jpg,\n",
    "    channels=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExtractJpegShape:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.image.extract_jpeg_shape(\n",
    "    PIL_jpg,\n",
    "    output_type=tf.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExtractJpegShape_1:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.image.extract_jpeg_shape(\n",
    "    jpg_image_cv2.tostring(),\n",
    "    output_type=tf.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfgfile_tf_image = tf.image.decode_image(\n",
    "    contents=encoded_jpg,\n",
    "    channels=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "print(type(tfgfile_tf_image))\n",
    "print(tfgfile_tf_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"is_jpeg/Equal:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(tf.image.is_jpeg(\n",
    "    jpg_image_cv2.tostring(),\n",
    "    name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"is_jpeg_1/Equal:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(tf.image.is_jpeg(\n",
    "    encoded_jpg,\n",
    "    name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '\\xff\\xd8\\xff\\xe0' in str(jpg_image_cv2.tostring()):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'2L\\\\\\\\<VdVlw}\\\\x90\\\\x9\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(jpg_image_cv2.tostring())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_image_cv2 = cv2.imread('/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/train/IMG_2385.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'2L\\\\\\\\<VdVlw}\\\\x90\\\\x9\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(jpg_image_cv2.tostring())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x96\\xa5\\xb5\\x93\\x\n"
     ]
    }
   ],
   "source": [
    "test3 = cv2.imread('/Users/johnmorin/Downloads/file.jpeg')\n",
    "print(str(test3.tostring())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xdd\\xdd\\xcd\\xdd\\x\n"
     ]
    }
   ],
   "source": [
    "test4 = cv2.imread('/Users/johnmorin/KaylaTek/tank_pic.jpg')\n",
    "print(str(test4.tostring())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.gfile.GFile('/Users/johnmorin/KaylaTek/tank_pic.jpg', 'rb') as fid:\n",
    "    tank_jpg = fid.read()\n",
    "str(tank_jpg)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExtractJpegShape_2:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.image.extract_jpeg_shape(\n",
    "    tank_jpg,\n",
    "    output_type=tf.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decode_image_12/cond_jpeg/Merge:0' shape=<unknown> dtype=uint8>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.image.decode_image(\n",
    "    contents=tank_jpg,\n",
    "    channels=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "omg = tf.image.decode_jpeg(\n",
    "    tank_jpg,\n",
    "    channels=0,\n",
    "    ratio=1,\n",
    "    fancy_upscaling=True,\n",
    "    try_recover_truncated=False,\n",
    "    acceptable_fraction=1,\n",
    "    dct_method='',\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(None)])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.gfile.GFile('/Users/johnmorin/Downloads/file.jpeg', 'rb') as fid:\n",
    "    file_jpg = fid.read()\n",
    "str(file_jpg)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.gfile.GFile('/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/train/IMG_2385.JPG', 'rb') as fid:\n",
    "    obj_jpg = fid.read()\n",
    "str(obj_jpg)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tankbool = tf.image.is_jpeg(\n",
    "    tank_jpg,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmorin/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "#a = tf.placeholder(tankbool)  #placeholder for a single boolean value\n",
    "b = tf.cond(\n",
    "        tf.equal(tankbool, tf.constant(True)), \n",
    "        lambda: tf.constant(10), \n",
    "        lambda: tf.constant(0))\n",
    "sess = tf.InteractiveSession()\n",
    "res = sess.run(b, feed_dict = {tankbool: True})\n",
    "sess.close()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff = '/Users/johnmorin/KaylaTek/Data/Flight_5_with_ground_truth/frame_000000.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'II*\\\\x00\\\\x08\\\\x00\\\\x0\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.gfile.GFile(tiff, 'rb') as fid:\n",
    "    tiff_obj = fid.read()\n",
    "str(tiff_obj)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
