{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, ArrayType\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .appName(\"sql.functions tests\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_train_loc = '/Users/johnmorin/KaylaTek/Data/images/train/*.tif'\n",
    "tiff_test_loc = '/Users/johnmorin/KaylaTek/Data/images/test/*.tif'\n",
    "tiff_train_labels = '/Users/johnmorin/KaylaTek/Data/images/training_data.csv'\n",
    "tiff_test_labels = '/Users/johnmorin/KaylaTek/Data/images/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_file_loc = '/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/train_labels.csv'\n",
    "#test_file_loc = '/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/test_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING_FILE_LOCATION = '/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/train/*.jpg'\n",
    "#TEST_FILE_LOCATION = '/Users/johnmorin/Documents/GitHub/Obj-Det-Tutorial/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images/train/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tif_image_df = spark.read.format('image').load('/Users/johnmorin/KaylaTek/Data/images/train/frame_000000.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_shape = tf.cast(tf.stack([1024, 1280, 3]), tf.int32)\n",
    "#image = tf.reshape(tf.decode_raw(encoded_inputs, tf.uint8), to_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'nine':\n",
    "        return 1\n",
    "    elif row_label == 'ten':\n",
    "        return 2\n",
    "    elif row_label == 'jack':\n",
    "        return 3\n",
    "    elif row_label == 'queen':\n",
    "        return 4\n",
    "    elif row_label == 'king':\n",
    "        return 5\n",
    "    elif row_label == 'ace':\n",
    "        return 6\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_files(label_filename):\n",
    "    df = pd.read_csv(label_filename)\n",
    "    grouped = df['filename'].unique()\n",
    "    \n",
    "    csv_df = pd.DataFrame()\n",
    "    for files in grouped:\n",
    "        mydf = df[df['filename'] == files]\n",
    "        #print(mydf.head())\n",
    "        height = int(mydf['h'].unique()[0])\n",
    "        width = int(mydf['w'].unique()[0])\n",
    "        filename = mydf.filename.unique()[0]\n",
    "        num_label = mydf['classes'].tolist()\n",
    "        label = mydf['classes_text'].tolist()\n",
    "        #print(list(label))\n",
    "        #num_label = mydf['class'].map(class_text_to_int).tolist()\n",
    "        # Creating proportional locations for the bounding boxes instead of pixel values\n",
    "        xmin = mydf['xmin'].map(lambda x: x/width).tolist()\n",
    "        ymin = mydf['ymin'].map(lambda x: x/height).tolist()\n",
    "        xmax = mydf['xmax'].map(lambda x: x/width).tolist()\n",
    "        ymax = mydf['ymax'].map(lambda x: x/height).tolist()\n",
    "        temp = pd.DataFrame({'image/filename':filename, 'image/width':width, 'image/height':height, \n",
    "                        'image/object/class/label':[num_label], 'image/object/bbox/xmin':[xmin], \n",
    "                        'image/object/bbox/ymin':[ymin],'image/object/bbox/xmax':[xmax],\n",
    "                        'image/object/bbox/ymax':[ymax], 'image/object/class/text':[label],\n",
    "                        # Change Number of Channels to correct number\n",
    "                        'image/channels': int(3)\n",
    "                        #'image/encoded': dataset_util.bytes_feature(encoded_inputs),\n",
    "                        })\n",
    "        csv_df = pd.concat([csv_df, temp])\n",
    "    csv_df.reset_index(inplace= True)\n",
    "    csv_df.drop('index', axis=1, inplace = True)\n",
    "    csv_df['image/format'] = '.tif'\n",
    "    return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF\n",
    "#cv2_udf = udf(lambda x: cv2.imread(x, 1).tostring(), BinaryType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenCV to read in binary for image file\n",
    "#image_df = image_df.withColumn('file_locs', image_df.image.origin.substr(6, 300))\n",
    "\n",
    "#image_df = image_df.withColumn('cv2', cv2_udf(image_df.file_locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df = spark.read.format('image').load(tiff_train_loc)\n",
    "image_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/Users/johnmorin/KaylaTek/Data/images/train/frame_000365.tif'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df.first().image.origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecord(pandas_df, tf_record_loc, image_location, which):\n",
    "    pand_df = sqlContext.createDataFrame(pandas_df)\n",
    "    image_df = spark.read.format('image').load(image_location)\n",
    "    if which is 'train':\n",
    "        image_df = image_df.withColumn('filename', image_df.image.origin.substr(50, 300))\n",
    "    if which is 'test':\n",
    "        image_df = image_df.withColumn('filename', image_df.image.origin.substr(49, 300))\n",
    "    combined_df = image_df.join(pand_df, \\\n",
    "                            image_df.filename == pand_df['image/filename'], \\\n",
    "                            'inner').drop(image_df.filename)\n",
    "    # Original Code to add encoded data to \n",
    "    #combined_df = combined_df.withColumn('image/encoded', combined_df['image'].data)\n",
    "    # Code to encode tiffs into binary format when pyspark won't read them\n",
    "    combined_df = combined_df.withColumn('image/source_id', combined_df.image.origin.substr(6, 300))\n",
    "    cv2_udf = udf(lambda x: cv2.imread(x, 1).tostring(), BinaryType())\n",
    "    combined_df = combined_df.withColumn('image/encoded', cv2_udf(combined_df['image/source_id']))\n",
    "    #print(combined_df.first())\n",
    "    # Cleaning up dataframe before writing it to tfrecord\n",
    "    combined_df = combined_df.drop('image')\n",
    "    \n",
    "    # Writing Pyspark Dataframe to tfrecord\n",
    "    combined_df.write.format('tfrecords').option('recordType', 'Example').save(tf_record_loc)\n",
    "    #combined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_label_files(tiff_train_labels)\n",
    "test_df = load_label_files(tiff_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecord(train_df, 'tf_tiff_train', tiff_train_loc, 'train')\n",
    "create_tfrecord(test_df, 'tf_tiff_test', tiff_test_loc, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_files = spark.read.format('csv') \\\n",
    "#    .option(\"header\", \"true\") \\\n",
    "#    .option(\"inferSchema\", 'true') \\\n",
    "#    .load('train_label_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords = '/tf_card_train/*.*'\n",
    "tf_single = 'pand_tf_train.record/part-r-00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rec = spark.read.format(\"tfrecords\").option(\"recordType\", \"Example\").load(tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rec.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
